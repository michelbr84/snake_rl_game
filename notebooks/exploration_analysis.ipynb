# exploration_analysis.ipynb

import pandas as pd
import matplotlib.pyplot as plt

# Carregar dados de exploração do DQN
dqn_data = pd.read_csv('dqn_training_data.csv', names=['Episode', 'Reward', 'Epsilon'])

# Visualizar taxa de exploração (epsilon) do DQN ao longo do tempo
plt.figure(figsize=(10, 5))
plt.plot(dqn_data['Episode'], dqn_data['Epsilon'], label='Epsilon (DQN)', color='purple')
plt.xlabel('Episodes')
plt.ylabel('Epsilon')
plt.title('Exploration Rate (Epsilon) - DQN')
plt.legend()
plt.show()

# Análise da Distribuição de Ações para A2C e PPO
# Carregar as ações dos agentes A2C e PPO ao longo dos episódios
# (Supondo que você tenha registrado as ações em arquivos separados durante o treinamento)

# Exemplo para carregamento dos dados de ações (separadamente para cada agente)
# a2c_actions = pd.read_csv('a2c_actions.csv', names=['Episode', 'Action'])
# ppo_actions = pd.read_csv('ppo_actions.csv', names=['Episode', 'Action'])

# Distribuição das ações para A2C
# plt.figure(figsize=(10, 5))
# a2c_actions['Action'].value_counts().plot(kind='bar', color='green')
# plt.xlabel('Action')
# plt.ylabel('Frequency')
# plt.title('Action Distribution - A2C')
# plt.show()

# Distribuição das ações para PPO
# plt.figure(figsize=(10, 5))
# ppo_actions['Action'].value_counts().plot(kind='bar', color='red')
# plt.xlabel('Action')
# plt.ylabel('Frequency')
# plt.title('Action Distribution - PPO')
# plt.show()
